import json
from bs4 import BeautifulSoup
from urllib.request import urlopen
from urllib.parse import unquote

url        = "https://no.wikipedia.org/wiki/Norges_kommuner"
page       = urlopen(url)
html_bytes = page.read()
html       = html_bytes.decode('utf-8')
soup       = BeautifulSoup(html, 'html.parser')

table = soup.find('table', class_='wikitable')
tds   = table.find_all('td')

def batch(iterable, n = 1):
    l = len(iterable)

    for ndx in range(0, l, n):
        yield iterable[ndx:min(ndx + n, l)]

kommuner = []
batches  = batch(tds, 9)
for i, td_batch in enumerate(batches):
    kommune = {'name': '', 'imageUrl': ''}
    for j, td in enumerate(td_batch):
        if j == 1:
            kommune['name'] = unquote(td.find('a').string)
            print('Fetching ' + str(i + 1) + ' of ' + str(int(len(tds) / 9)))
        elif j == 7:
            image_url = 'https://no.wikipedia.org' + td.find('a').get('href')
            if 'Spesial' in image_url:
                kommune['imageUrl'] = image_url
            else:
                image_page       = urlopen(image_url)
                image_html_bytes = image_page.read()
                image_html       = image_html_bytes.decode('utf-8')
                image_soup       = BeautifulSoup(image_html, 'html.parser')

                kommune['imageUrl'] = 'https:' + image_soup.find('a', class_='internal').get('href')

    kommuner.append(kommune)

with open('data.json', 'w', encoding = 'utf-8') as f:
    json.dump(kommuner, f, ensure_ascii = False, indent = 4)
